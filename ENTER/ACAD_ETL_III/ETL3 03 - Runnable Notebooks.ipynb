{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n<img src=\"https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png\" style=\"float: left: margin: 20px\"/>\n# Runnable Notebooks\n\nApache Spark&trade; and Databricks&reg; notebooks can be run, opening the door for automated workflows.\n\n## In this lesson you:\n* Parameterize notebooks using widgets\n* Execute single and multiple notebooks with dependencies\n* Pass variables into notebooks using widgets\n\n## Audience\n* Primary Audience: Data Engineers\n* Additional Audiences: Data Scientists and Data Pipeline Engineers\n\n## Prerequisites\n* Web browser: Chrome\n* A cluster configured with **8 cores** and **DBR 6.2**\n* Course: ETL Part 1 from <a href=\"https://academy.databricks.com/\" target=\"_blank\">Databricks Academy</a>\n* Course: ETL Part 2 from <a href=\"https://academy.databricks.com/\" target=\"_blank\">Databricks Academy</a>"],"metadata":{}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the<br/>\nstart of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/6a1rc4aaif?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/6a1rc4aaif?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### A Step Toward Full Automation\n\nNotebooks are one--and not the only--way of interacting with the Spark and Databricks environment.  Notebooks can be executed independently and as recurring jobs.  They can also be exported and versioned using git.  Python files and Scala/Java jars can be executed against a Databricks cluster as well, allowing full integration with a developer's normal workflow.  Since notebooks can be executed like code files and compiled binaries, they offer a way of building production pipelines.\n\nFunctional programming design principles aid in thinking about pipelines.  In functional programming, your code always has known inputs and outputs without any side effects.  In the case of automating notebooks, coding notebooks in this way helps reduce any unintended side effects where each stage in a pipeline can operate independently from the rest.\n\nMore complex workflows using notebooks require managing dependencies between tasks and passing parameters into notebooks.  Dependency management can done by chaining notebooks together, for instance to run reporting logic after having completed a database write. Sometimes, when these pipelines become especially complex, chaining notebooks together isn't sufficient. In those cases, scheduling with Apache Airflow has become the preferred solution. Notebook widgets can be used to pass parameters to a notebook when the parameters are determined at runtime.\n\n<div><img src=\"https://files.training.databricks.com/images/eLearning/ETL-Part-3/notebook-workflows.png\" style=\"height: 400px; margin: 20px\"/></div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Widgets\n\nWidgets allow for the customization of notebooks without editing the code itself.  They also allow for passing parameters into notebooks.  There are 4 types of widgets:\n\n| Type          | Description                                                                                        |\n|:--------------|:---------------------------------------------------------------------------------------------------|\n| `text`        | Input a value in a text box.                                                                       |\n| `dropdown`    | Select a value from a list of provided values.                                                     |\n| `combobox`    | Combination of text and dropdown. Select a value from a provided list or input one in the text box.|\n| `multiselect` | Select one or more values from a list of provided values.                                          |\n\nWidgets are Databricks utility functions that can be accessed using the `dbutils.widgets` package and take a name, default value, and values (if not a `text` widget).\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> Check out <a href=\"https://docs.azuredatabricks.net/user-guide/notebooks/widgets.html#id1\" target=\"_blank\">the Databricks documentation on widgets for additional information </a>"],"metadata":{}},{"cell_type":"code","source":["dbutils.widgets.dropdown(\"MyWidget\", \"1\", [str(x) for x in range(1, 5)])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["Notice the widget created at the top of the screen.  Choose a number from the dropdown menu.  Now, bring that value into your code using the `get` method."],"metadata":{}},{"cell_type":"code","source":["dbutils.widgets.get(\"MyWidget\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[61]: &#39;1&#39;</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["Clear the widgets using either `remove()` or `removeAll()`"],"metadata":{}},{"cell_type":"code","source":["dbutils.widgets.removeAll()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["While great for adding parameters to notebooks and dashboards, widgets also allow us to pass parameters into notebooks when we run them like a Python or JAR file."],"metadata":{}},{"cell_type":"markdown","source":["### Running Notebooks\n\nThere are two options for running notebooks.  The first is using `dbutils.notebook.run(\"<path>\", \"<timeout>\")`.  This will run the notebook.  [Take a look at this notebook first to see what it accomplishes.]($./Runnable/Runnable-1 )\n\nNow run the notebook with the following command."],"metadata":{}},{"cell_type":"code","source":["return_value = dbutils.notebook.run(\"./Runnable/Runnable-1\", 30)\n\nprint(\"Notebook successfully ran with return value: {}\".format(return_value))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o2952._run.\n: java.lang.IllegalArgumentException: requirement failed: To enable notebook workflows, please upgrade your Databricks subscription.\n\tat scala.Predef$.require(Predef.scala:224)\n\tat com.databricks.dbutils_v1.impl.NotebookUtilsImpl.checkEnabled(NotebookUtilsImpl.scala:53)\n\tat com.databricks.dbutils_v1.impl.NotebookUtilsImpl.setContext(NotebookUtilsImpl.scala:165)\n\tat com.databricks.dbutils_v1.impl.NotebookUtilsImpl._run(NotebookUtilsImpl.scala:85)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"ansi-red-fg\">IllegalArgumentException</span>                  Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1055298992984107&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>return_value <span class=\"ansi-blue-fg\">=</span> dbutils<span class=\"ansi-blue-fg\">.</span>notebook<span class=\"ansi-blue-fg\">.</span>run<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;./Runnable/Runnable-1&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">30</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Notebook successfully ran with return value: {}&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>return_value<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/tmp/1587134507493-0/dbutils.py</span> in <span class=\"ansi-cyan-fg\">run</span><span class=\"ansi-blue-fg\">(self, path, timeout_seconds, arguments, _NotebookHandler__databricks_internal_cluster_spec)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>                 arguments<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 __databricks_internal_cluster_spec<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">--&gt; 136</span><span class=\"ansi-red-fg\">                 self.shell.currentJobGroup)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    137</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    138</span>         <span class=\"ansi-green-fg\">def</span> __repr__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     77</span>                 <span class=\"ansi-green-fg\">raise</span> QueryExecutionException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     78</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;java.lang.IllegalArgumentException: &#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 79</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> IllegalArgumentException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     80</span>             <span class=\"ansi-green-fg\">raise</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     81</span>     <span class=\"ansi-green-fg\">return</span> deco\n\n<span class=\"ansi-red-fg\">IllegalArgumentException</span>: &#39;requirement failed: To enable notebook workflows, please upgrade your Databricks subscription.&#39;</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["Notice how the `Runnable-1` notebook ends with the command `dbutils.notebook.exit(\"returnValue\")`.  This is a `string` that's passed back into the running notebook's environment."],"metadata":{}},{"cell_type":"markdown","source":["Run the following cell and note how the variable doesn't exist."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\nThis variable is not passed into our current environment.  The difference between `dbutils.notebook.run()` and `%run` is that the parent notebook will inherit variables from the ran notebook with `%run`.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> This is how the classroom setup script at the beginning of each lesson works.  Among other things, it defines the variable `userhome` for you so that you have a unique write destination from colleagues on your Databricks workspace"],"metadata":{}},{"cell_type":"code","source":["#  @  ./Runnable/Runnable-1"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["%run ./Runnable/Runnable-1"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["Now this variable is available for use in this notebook"],"metadata":{}},{"cell_type":"code","source":["print(my_variable)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["### Parameter Passing and Debugging\n\nNotebook widgets allow us to pass parameters into notebooks.  This can be done in the form of a dictionary that maps the widget name to a value as a `string`.\n\n[Take a look at the second notebook to see what it accomplishes.]($./Runnable/Runnable-2 )"],"metadata":{}},{"cell_type":"markdown","source":["Pass your parameters into `dbutils.notebook.run` and save the resulting return value"],"metadata":{}},{"cell_type":"code","source":["basePath =  \"{}/etl3p/\".format(getUserhome())\ndest_path = \"{}/academy/raw_logs.parquet\".format(basePath)\n\nresult = dbutils.notebook.run(\"./Runnable/Runnable-2\", 60, {\"date\": \"11-27-2013\", \"dest_path\": dest_path})"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["Click on `Notebook job #XXX` above to view the output of the notebook.  **This is helpful for debugging any problems.**"],"metadata":{}},{"cell_type":"markdown","source":["Parse the JSON string results"],"metadata":{}},{"cell_type":"code","source":["import json\nprint(json.loads(result))"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["Now look at what this accomplished: cell phone logs were parsed corresponding to the date of the parameter passed into the notebook.  The results were saved to the given destination path."],"metadata":{}},{"cell_type":"code","source":["display(spark.read.parquet(dest_path))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1055298992984121&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>display<span class=\"ansi-blue-fg\">(</span>spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>parquet<span class=\"ansi-blue-fg\">(</span>dest_path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;dest_path&#39; is not defined</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["-sandbox\n### Dependency Management, Timeouts, Retries, and Passing Data\n\nRunning notebooks can allow for more advanced workflows in the following ways:<br><br>\n\n* Managing **dependencies** can be ensured by running a notebook that triggers other notebooks in the desired order\n* Setting **timeouts** ensures that jobs have a set limit on when they must either complete or fail\n* **Retry logic** ensures that fleeting failures do not prevent the proper execution of a notebook\n* **Data can passed** between notebooks by saving the data to a blob store or table and passing the path as an exit parameter\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> Check out <a href=\"https://docs.azuredatabricks.net/user-guide/notebooks/notebook-workflows.html\" target=\"_blank\">the Databricks documentation on Notebook Workflows for additional information </a>"],"metadata":{}},{"cell_type":"markdown","source":["## Exercise 1: Building a Generalized Notebook\n\nBuild a notebook that allows for customization using input parameters"],"metadata":{}},{"cell_type":"markdown","source":["### Step 1: Filter an Hour of Log Data\n\n[Fill out the `Runnable-3` notebook]($./Runnable/Runnable-3 ) that takes accomplishes the following (it's helpful to open this in another tab):<br><br>\n\n1. Takes two parameters: `hour` and `output_path`\n1. Reads the following log file: `/mnt/training/EDGAR-Log-20170329/enhanced/EDGAR-Log-20170329-sample.parquet`\n1. Filters the data for the hour provided\n1. Writes the result to the `output_path`\n1. Exits with the `output_path` as the exit parameter"],"metadata":{}},{"cell_type":"code","source":["path = \"{}/hour_03.parquet\".format(basePath)\n\ndbutils.notebook.run(\"./Runnable/Runnable-3\", 60, {\"hour\": \"03\", \"output_path\": path})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1055298992984125&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>path <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;{}/hour_03.parquet&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>basePath<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> dbutils<span class=\"ansi-blue-fg\">.</span>notebook<span class=\"ansi-blue-fg\">.</span>run<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;./Runnable/Runnable-3&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">60</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#34;hour&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#34;03&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;output_path&#34;</span><span class=\"ansi-blue-fg\">:</span> path<span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;basePath&#39; is not defined</div>"]}}],"execution_count":35},{"cell_type":"code","source":["# TEST - Run this cell to test your solution\nimport random\n\nr = str(random.randint(0, 10**10))\n_path = \"{}/hour_08_{}.parquet\".format(basePath, r)\n\n_returnValue = dbutils.notebook.run(\"./Runnable/Runnable-3\", 60, {\"hour\": \"08\", \"output_path\": _path})\n_df = spark.read.parquet(_returnValue)\n\ndbTest(\"ET3-P-03-01-01\", True, _path == _returnValue)\ndbTest(\"ET3-P-03-01-02\", 54206, _df.count())\n\ndbutils.fs.rm(_path, True)\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1055298992984126&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> r <span class=\"ansi-blue-fg\">=</span> str<span class=\"ansi-blue-fg\">(</span>random<span class=\"ansi-blue-fg\">.</span>randint<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">**</span><span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\"> </span>_path <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;{}/hour_08_{}.parquet&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>basePath<span class=\"ansi-blue-fg\">,</span> r<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> _returnValue <span class=\"ansi-blue-fg\">=</span> dbutils<span class=\"ansi-blue-fg\">.</span>notebook<span class=\"ansi-blue-fg\">.</span>run<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;./Runnable/Runnable-3&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">60</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#34;hour&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#34;08&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;output_path&#34;</span><span class=\"ansi-blue-fg\">:</span> _path<span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;basePath&#39; is not defined</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["## Review\n**Question:** How can I start to transition from notebooks to production environments?  \n**Answer:** Runnable notebooks are the first step towards transitioning into production environments since they allow us to generalize and parameterize our code.  There are other options, including running Python files and Scala/Java jars against a cluster as well.\n\n**Question:** How does passing parameters into and out of notebooks work?  \n**Answer:** Widgets allow for the customization of notebooks and passing parameters into them.  This takes place in the form of a dictionary (Python) or map (Scala) of key/value pairs that match the names of widgets.  Only strings can be passed out of a notebook as an exit parameter.\n\n**Question:** Since I can only pass strings of a limited length out of a notebook, how can I pass data out of a notebook?  \n**Answer:** The preferred way is to save your data to a blob store or Spark table.  On the notebook's exit, pass the location of that data as a string.  It can then be easily imported and manipulated in another notebook."],"metadata":{}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Cleanup\""],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["## Next Steps\n\nStart the next lesson, [Scheduling Jobs Programatically]($./ETL3 04 - Scheduling Jobs Programatically )."],"metadata":{}},{"cell_type":"markdown","source":["## Additional Topics & Resources\n\n**Q:** How can I integrate Databricks with more complex workflow schedulers like Apache Airflow?  \n**A:** Check out the Databricks blog <a href=\"https://databricks.com/blog/2017/07/19/integrating-apache-airflow-with-databricks.html\" target=\"_blank\">Integrating Apache Airflow with Databricks</a>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"ETL3 03 - Runnable Notebooks","notebookId":1055298992984092},"nbformat":4,"nbformat_minor":0}
