{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n<img src=\"https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png\" style=\"float: left: margin: 20px\"/>\n\n# Structured Streaming\n\n<p>\nStructured Streaming is an efficient way to ingest large quantities of data from a variety of sources.<br> \nThis course is intended to teach you how how to use Structured Streaming to ingest data from files and<br>\npublisher-subscribe systems. Starting with the fundamentals of streaming systems, we introduce concepts<br> \nsuch as reading streaming data, writing out streaming data to directories, displaying streaming data and<br>\nTriggers. We discuss the problems associated with trying to aggregate streaming data and then teach<br>\nhow to solve this problem using structures called windows and expiring old data using watermarking.<br>\nFinally, we examine how to connect Structured Streaming with popular publish-subscribe systems to <br>\nstream data from Wikipedia.\n</p>\n\n## Upon completion of this course, students should be able to\n\n* Read, write and display streaming data.\t\n* Apply time windows and watermarking to aggregate streaming data.\n* Use a publish-subscribe system to stream wikipedia data in order to visualize meaningful analytics\t\n\n## Prerequisites\n* Web browser: **Chrome**\n* A cluster configured with **8 cores** and **DBR 6.3**\n* Suggested Courses from <a href=\"https://academy.databricks.com/\" target=\"_blank\">Databricks Academy</a>:\n  - ETL Part 1\n  - Spark-SQL"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n\n<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Before You Start</h2>\n\nBefore starting this course, you will need to create a cluster and attach it to this notebook.\n\nPlease configure your cluster to use Databricks Runtime version **6.3** which includes:\n- Python Version 3.x\n- Scala Version 2.11\n- Apache Spark 2.4.4\n\n<img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> Do not use an ML or GPU accelerated runtimes\n\nStep-by-step instructions for creating a cluster are included here:\n- <a href=\"https://www.databricks.training/step-by-step/creating-clusters-on-azure\" target=\"_blank\">Azure Databricks</a>\n- <a href=\"https://www.databricks.training/step-by-step/creating-clusters-on-aws\" target=\"_blank\">Databricks on AWS</a>\n- <a href=\"https://www.databricks.training/step-by-step/creating-clusters-on-ce\" target=\"_blank\">Databricks Community Edition (CE)</a>\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> This courseware has been tested against the specific DBR listed above. Using an untested DBR may yield unexpected results and/or various errors. If the required DBR has been deprecated, please <a href=\"https://academy.databricks.com/\" target=\"_blank\">download an updated version of this course</a>."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup & Classroom-Cleanup<br>\nIn general, all courses are designed to run on one of the following Databricks platforms:\n* Databricks Community Edition (CE)\n* Databricks (an AWS hosted service)\n* Azure-Databricks (an Azure-hosted service)\n\n<img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> Some features are not available on the Community Edition, which limits the ability of some courses to be executed in that environment. Please see the course's prerequisites for specific information on this topic.\n\n<img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> Additionally, private installations of Databricks (e.g., accounts provided by your employer) may have other limitations imposed, such as aggressive permissions and or language restrictions such as prohibiting the use of Scala which will further inhibit some courses from being executed in those environments.\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** All courses provided by Databricks Academy rely on custom variables, functions, and settings to provide you with the best experience possible.\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/mkslslo1zl?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/mkslslo1zl?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n\n<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> The Problem</h2>\n\nWe have a stream of data coming in from a TCP-IP socket, Kafka, Kinesis or other sources...\n\nThe data is coming in faster than it can be consumed\n\nHow do we solve this problem?\n\n<img src=\"https://files.training.databricks.com/images/drinking-from-the-fire-hose.png\"  style=\"height: 300px;\"/>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n\n<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> The Micro-Batch Model</h2>\n\nMany APIs solve this problem by employing a Micro-Batch model.\n\nIn this model, we take our firehose of data and collect data for a set interval of time (the **Trigger Interval**).\n\nIn our example, the **Trigger Interval** is two seconds.\n\n<img src=\"https://files.training.databricks.com/images/streaming-timeline.png\" style=\"height: 150px;\"/>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n\n<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Processing the Micro-Batch</h2>\n\nFor each interval, our job is to process the data from the previous [two-second] interval.\n\nAs we are processing data, the next batch of data is being collected for us.\n\nIn our example, we are processing two seconds worth of data in about one second.\n\n<img src=\"https://files.training.databricks.com/images/streaming-timeline-1-sec.png\" style=\"height: 150px;\">"],"metadata":{}},{"cell_type":"markdown","source":["### What happens if we don't process the data fast enough when reading from a TCP/IP Stream?"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n<html>\n  <head>\n    <script src=\"https://files.training.databricks.com/static/assets/spark-ilt/labs.js\"></script>\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"https://files.training.databricks.com/static/assets/spark-ilt/labs.css\">\n  </head>\n  <body>\n    <div id=\"the-button\"><button style=\"width:15em\" onclick=\"block('the-answer', 'the-button')\">Continue Reading</button></div>\n\n    <div id=\"the-answer\" style=\"display:none\">\n      <p>In the case of a TCP/IP stream, we will most likely drop packets.</p>\n      <p>In other words, we would be losing data.</p>\n      <p>If this is an IoT device measuring the outside temperature every 15 seconds, this might be OK.</p>\n      <p>If this is a critical shift in stock prices, you could be out thousands of dollars.</p>\n    </div>\n  </body>\n</html>"],"metadata":{}},{"cell_type":"markdown","source":["### What happens if we don't process the data fast enough when reading from a pubsub system like Kafka?"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n<html>\n  <head>\n    <script src=\"https://files.training.databricks.com/static/assets/spark-ilt/labs.js\"></script>\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"https://files.training.databricks.com/static/assets/spark-ilt/labs.css\">\n  </head>\n  <body>\n    <div id=\"the-button\"><button style=\"width:15em\" onclick=\"block('the-answer', 'the-button')\">Continue Reading</button></div>\n\n    <div id=\"the-answer\" style=\"display:none\">\n      <p>In the case of a pubsub system, it simply means we fall further behind.</p>\n      <p>Eventually, the pubsub system would reach resource limits inducing other problems.</p>\n      <p>However, we can always re-launch the cluster with enough cores to catch up and stay current.</p>\n    </div>\n  </body>\n</html>"],"metadata":{}},{"cell_type":"markdown","source":["Our goal is simply to process the data for the previous interval before data from the next interval arrives."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n\n<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> From Micro-Batch to Table</h2>\n\nIn Apache Spark, we treat such a stream of **micro-batches** as continuous updates to a table.\n\nThe developer then defines a query on this **input table**, as if it were a static table.\n\nThe computation on the input table is then pushed to a **results table**.\n\nAnd finally, the results table is written to an output **sink**. \n\n<img src=\"https://files.training.databricks.com/images/eLearning/Delta/stream2rows.png\" style=\"height: 300px\"/>"],"metadata":{}},{"cell_type":"markdown","source":["In general, Spark Structured Streams consist of two parts:\n* The **Input source** such as \n  * Kafka\n  * Azure Event Hub\n  * Files on a distributed system\n  * TCP-IP sockets\n* And the **Sinks** such as\n  * Kafka\n  * Azure Event Hub\n  * Various file formats\n  * The system console\n  * Apache Spark tables (memory sinks)\n  * The completely custom `foreach()` iterator"],"metadata":{}},{"cell_type":"markdown","source":["### Update Triggers\nDevelopers define **triggers** to control how frequently the **input table** is updated. \n\nEach time a trigger fires, Spark checks for new data (new rows for the input table), and updates the result.\n\nFrom the docs for `DataStreamWriter.trigger(Trigger)`:\n> The default value is ProcessingTime(0) and it will run the query as fast as possible.\n\nAnd the process repeats in perpetuity."],"metadata":{}},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Summary</h2>\n\nUse cases for streaming include bank card transactions, log files, Internet of Things (IoT) device data, video game play events and countless others.\n\nSome key properties of streaming data include:\n* Data coming from a stream is typically not ordered in any way\n* The data is streamed into a **data lake**\n* The data is coming in faster than it can be consumed\n* Streams are often chained together to form a data pipeline\n* Streams don't have to run 24/7:\n  * Consider the new log files that are processed once an hour\n  * Or the financial statement that is processed once a month"],"metadata":{}},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Review Questions</h2>\n\n**Question:** What is Structured Streaming?<br>\n**Answer:** A stream is a sequence of data that is made available over time.<br>\nStructured Streaming where we treat a <b>stream</b> of data as a table to which data is continously appended.<br>\nThe developer then defines a query on this input table, as if it were a static table, to compute a final result table that will be written to an output <b>sink</b>. \n.\n\n**Question:** What purpose do triggers serve?<br>\n**Answer:** Developers define triggers to control how frequently the input table is updated.\n\n**Question:** How does micro batch work?<br>\n**Answer:** We take our firehose of data and collect data for a set interval of time (the Trigger Interval).<br>\nFor each interval, our job is to process the data from the previous time interval.<br>\nAs we are processing data, the next batch of data is being collected for us."],"metadata":{}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nDuring the course of this lesson, files, tables, and other artifacts may have been created.\n\nThese resources create clutter, consume resources (generally in the form of storage), and may potentially incur some [minor] long-term expense.\n\nYou can remove these artifacts by running the **`Classroom-Cleanup`** cell below."],"metadata":{}},{"cell_type":"code","source":["%run ./Includes/Classroom-Cleanup"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Next Steps</h2>\n\nStart the next lesson, [Streaming Concepts]($./SS 02 - Streaming Concepts)."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"SS 01 - Introduction","notebookId":4416930934983279},"nbformat":4,"nbformat_minor":0}
